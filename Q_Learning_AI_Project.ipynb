{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctyl-8mmY9is"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N05lfFIPZqWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AdpFVfy6ya9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d5c99c-7eb7-4a00-ad5b-78ccbce803cd"
      },
      "source": [
        "#define the shape of the environment (i.e., its states)\n",
        "environment_rows = 3\n",
        "environment_columns = 3\n",
        "\n",
        "#Create a 3D numpy array to hold the current Q-values for each state and action pair: Q(s, a)\n",
        "#The array contains 11 rows and 11 columns (to match the shape of the environment), as well as a third \"action\" dimension.\n",
        "#The \"action\" dimension consists of 4 layers that will allow us to keep track of the Q-values for each possible action in\n",
        "#each state (see next cell for a description of possible actions).\n",
        "#The value of each (state, action) pair is initialized to 0.\n",
        "q_values = np.zeros((environment_rows, environment_columns, 4))\n",
        "print(q_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define actions\n",
        "#numeric action codes: 0 = up, 1 = right, 2 = down, 3 = left\n",
        "actions = ['up', 'right', 'down', 'left']"
      ],
      "metadata": {
        "id": "RKxn0LriZP8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Create a 2D numpy array to hold the rewards for each state.\n",
        "# #The array contains 11 rows and 11 columns (to match the shape of the environment), and each value is initialized to -100.\n",
        "# rewards = np.full((environment_rows, environment_columns), -100.)\n",
        "# rewards[0, 0] = 100. #set the reward for the packaging area (i.e., the goal) to 100\n",
        "# #define aisle locations (i.e., white squares) for rows 1 through 9\n",
        "# aisles = {} #store locations in a dictionary\n",
        "# aisles[1] = [i for i in range(1, 10)]\n",
        "# aisles[2] = [1, 7, 9]\n",
        "# aisles[3] = [i for i in range(1, 8)]\n",
        "# aisles[3].append(9)\n",
        "# aisles[4] = [3, 7]\n",
        "# aisles[5] = [i for i in range(11)]\n",
        "# aisles[6] = [5]\n",
        "# aisles[7] = [i for i in range(1, 10)]\n",
        "# aisles[8] = [3, 7]\n",
        "# aisles[9] = [i for i in range(11)]\n",
        "# #set the rewards for all aisle locations (i.e., white squares)\n",
        "# for row_index in range(1, 10):\n",
        "#   for column_index in aisles[row_index]:\n",
        "#     rewards[row_index, column_index] = -1.\n",
        "#       # print(column_index)\n",
        "# #print rewards matrix\n",
        "# for row in rewards:\n",
        "#   print(row)\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "environment_rows = 3\n",
        "environment_columns = 3\n",
        "\n",
        "rewards = np.full((environment_rows, environment_columns), -100.)\n",
        "rewards[0, 0] = 100.\n",
        "\n",
        "aisles = {}\n",
        "aisles[1] = [i for i in range(1, environment_columns)]\n",
        "aisles[2] = [i for i in range(environment_columns)]\n",
        "\n",
        "for row_index in range(1, environment_rows):\n",
        "    for column_index in aisles[row_index]:\n",
        "        rewards[row_index, column_index] = -1.\n",
        "\n",
        "# Print rewards matrix\n",
        "\n",
        "\n",
        "rewards[0][1] = -1\n",
        "\n",
        "for row in rewards:\n",
        "    print(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk5l9-yjZdHs",
        "outputId": "cb74f3fc-8a55-47d7-aea1-153510cb7bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 100.   -1. -100.]\n",
            "[-100.   -1.   -1.]\n",
            "[-1. -1. -1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define a function that determines if the specified location is a terminal state\n",
        "def is_terminal_state(current_row_index, current_column_index):\n",
        "  #if the reward for this location is -1, then it is not a terminal state (i.e., it is a 'white square')\n",
        "  if rewards[current_row_index, current_column_index] == -1.:\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "#define a function that will choose a random, non-terminal starting location\n",
        "def get_starting_location():\n",
        "  #get a random row and column index\n",
        "  current_row_index = np.random.randint(environment_rows)\n",
        "  current_column_index = np.random.randint(environment_columns)\n",
        "  #continue choosing random row and column indexes until a non-terminal state is identified\n",
        "  #(i.e., until the chosen state is a 'white square').\n",
        "  while is_terminal_state(current_row_index, current_column_index):\n",
        "    current_row_index = np.random.randint(environment_rows)\n",
        "    current_column_index = np.random.randint(environment_columns)\n",
        "  return current_row_index, current_column_index\n",
        "#define an epsilon greedy algorithm that will choose which action to take next (i.e., where to move next)\n",
        "def get_next_action(current_row_index, current_column_index, epsilon):\n",
        "  #if a randomly chosen value between 0 and 1 is less than epsilon,\n",
        "  #then choose the most promising value from the Q-table for this state.\n",
        "  if np.random.random() < epsilon:\n",
        "    return np.argmax(q_values[current_row_index, current_column_index])\n",
        "  else: #choose a random action\n",
        "    return np.random.randint(4)\n",
        "#define a function that will get the next location based on the chosen action\n",
        "def get_next_location(current_row_index, current_column_index, action_index):\n",
        "  new_row_index = current_row_index\n",
        "  new_column_index = current_column_index\n",
        "  if actions[action_index] == 'up' and current_row_index > 0:\n",
        "    new_row_index -= 1\n",
        "  elif actions[action_index] == 'right' and current_column_index < environment_columns - 1:\n",
        "    new_column_index += 1\n",
        "  elif actions[action_index] == 'down' and current_row_index < environment_rows - 1:\n",
        "    new_row_index += 1\n",
        "  elif actions[action_index] == 'left' and current_column_index > 0:\n",
        "    new_column_index -= 1\n",
        "  return new_row_index, new_column_index\n",
        "#Define a function that will get the shortest path between any location within the warehouse that\n",
        "#the robot is allowed to travel and the item packaging location.\n",
        "def get_shortest_path(start_row_index, start_column_index):\n",
        "  #return immediately if this is an invalid starting location\n",
        "  if is_terminal_state(start_row_index, start_column_index):\n",
        "    return []\n",
        "  else: #if this is a 'legal' starting location\n",
        "    current_row_index, current_column_index = start_row_index, start_column_index\n",
        "    shortest_path = []\n",
        "    shortest_path.append([current_row_index, current_column_index])\n",
        "    #continue moving along the path until we reach the goal (i.e., the item packaging location)\n",
        "    while not is_terminal_state(current_row_index, current_column_index):\n",
        "      #get the best action to take\n",
        "      action_index = get_next_action(current_row_index, current_column_index, 1.)\n",
        "      #move to the next location on the path, and add the new location to the list\n",
        "      current_row_index, current_column_index = get_next_location(current_row_index, current_column_index, action_index)\n",
        "      shortest_path.append([current_row_index, current_column_index])\n",
        "    return shortest_path"
      ],
      "metadata": {
        "id": "CxzhlG9SZgv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define training parameters\n",
        "epsilon = 0.9 #the percentage of time when we should take the best action (instead of a random action)\n",
        "discount_factor = 0.9 #discount factor for future rewards\n",
        "learning_rate = 0.9 #the rate at which the agent should learn\n",
        "#run through 1000 training episodes\n",
        "for episode in range(5):\n",
        "  #get the starting location for this episode\n",
        "  row_index, column_index = get_starting_location()\n",
        "  #continue taking actions (i.e., moving) until we reach a terminal state\n",
        "  #(i.e., until we reach the item packaging area or crash into an item storage location)\n",
        "  print(\"episode:: \", episode)\n",
        "  while not is_terminal_state(row_index, column_index):\n",
        "    #choose which action to take (i.e., where to move next)\n",
        "    action_index = get_next_action(row_index, column_index, epsilon)\n",
        "    #perform the chosen action, and transition to the next state (i.e., move to the next location)\n",
        "    old_row_index, old_column_index = row_index, column_index #store the old row and column indexes\n",
        "    row_index, column_index = get_next_location(row_index, column_index, action_index)\n",
        "    #receive the reward for moving to the new state, and calculate the temporal difference\n",
        "    reward = rewards[row_index, column_index]\n",
        "    old_q_value = q_values[old_row_index, old_column_index, action_index]\n",
        "    temporal_difference = reward + (discount_factor * np.max(q_values[row_index, column_index])) - old_q_value\n",
        "    #update the Q-value for the previous state and action pair\n",
        "    new_q_value = old_q_value + (learning_rate * temporal_difference)\n",
        "    q_values[old_row_index, old_column_index, action_index] = new_q_value\n",
        "\n",
        "\n",
        "    # for q in q_values:\n",
        "    print(q_values)\n",
        "print('Training complete!')"
      ],
      "metadata": {
        "id": "o5QV77c0Z1Cg",
        "outputId": "9b5b62ad-bd4a-4ba5-81fc-4ecd1530b05f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode::  0\n",
            "[[[   0.            0.            0.            0.        ]\n",
            "  [  89.         -100.           79.1         100.        ]\n",
            "  [   0.            0.            0.            0.        ]]\n",
            "\n",
            " [[   0.            0.            0.            0.        ]\n",
            "  [  89.           70.19         70.19       -100.        ]\n",
            "  [-100.           70.19         62.171        79.1       ]]\n",
            "\n",
            " [[-100.           70.19         62.17099999   62.171     ]\n",
            "  [  79.1          62.171        70.19         62.171     ]\n",
            "  [  70.19         62.17099994   62.171        70.18999999]]]\n",
            "[[[   0.            0.            0.            0.        ]\n",
            "  [  89.         -100.           79.1         100.        ]\n",
            "  [   0.            0.            0.            0.        ]]\n",
            "\n",
            " [[   0.            0.            0.            0.        ]\n",
            "  [  89.           70.19         70.19       -100.        ]\n",
            "  [-100.           70.19         62.171        79.1       ]]\n",
            "\n",
            " [[-100.           70.19         62.17099999   62.171     ]\n",
            "  [  79.1          62.171        70.19         62.171     ]\n",
            "  [  70.19         62.17099994   62.171        70.18999999]]]\n",
            "[[[   0.            0.            0.            0.        ]\n",
            "  [  89.         -100.           79.1         100.        ]\n",
            "  [   0.            0.            0.            0.        ]]\n",
            "\n",
            " [[   0.            0.            0.            0.        ]\n",
            "  [  89.           70.19         70.19       -100.        ]\n",
            "  [-100.           70.19         62.171        79.1       ]]\n",
            "\n",
            " [[-100.           70.19         62.17099999   62.171     ]\n",
            "  [  79.1          62.171        70.19         62.171     ]\n",
            "  [  70.19         62.17099994   62.171        70.18999999]]]\n",
            "[[[   0.            0.            0.            0.        ]\n",
            "  [  89.         -100.           79.1         100.        ]\n",
            "  [   0.            0.            0.            0.        ]]\n",
            "\n",
            " [[   0.            0.            0.            0.        ]\n",
            "  [  89.           70.19         70.19       -100.        ]\n",
            "  [-100.           70.19         62.171        79.1       ]]\n",
            "\n",
            " [[-100.           70.19         62.17099999   62.171     ]\n",
            "  [  79.1          62.171        70.19         62.171     ]\n",
            "  [  70.19         62.17099994   62.171        70.18999999]]]\n",
            "episode::  1\n",
            "[[[   0.            0.            0.            0.        ]\n",
            "  [  89.         -100.           79.1         100.        ]\n",
            "  [   0.            0.            0.            0.        ]]\n",
            "\n",
            " [[   0.            0.            0.            0.        ]\n",
            "  [  89.           70.19         70.19       -100.        ]\n",
            "  [-100.           70.19         62.171        79.1       ]]\n",
            "\n",
            " [[-100.           70.19         62.17099999   62.171     ]\n",
            "  [  79.1          62.171        70.19         62.171     ]\n",
            "  [  70.19         62.17099994   62.171        70.18999999]]]\n",
            "[[[   0.            0.            0.            0.        ]\n",
            "  [  89.         -100.           79.1         100.        ]\n",
            "  [   0.            0.            0.            0.        ]]\n",
            "\n",
            " [[   0.            0.            0.            0.        ]\n",
            "  [  89.           70.19         70.19       -100.        ]\n",
            "  [-100.           70.19         62.171        79.1       ]]\n",
            "\n",
            " [[-100.           70.19         62.17099999   62.171     ]\n",
            "  [  79.1          62.171        70.19         62.171     ]\n",
            "  [  70.19         62.17099994   62.171        70.18999999]]]\n",
            "episode::  2\n",
            "[[[   0.            0.            0.            0.        ]\n",
            "  [  89.         -100.           79.1         100.        ]\n",
            "  [   0.            0.            0.            0.        ]]\n",
            "\n",
            " [[   0.            0.            0.            0.        ]\n",
            "  [  89.           70.19         70.19       -100.        ]\n",
            "  [-100.           70.19         62.171        79.1       ]]\n",
            "\n",
            " [[-100.           70.19         62.17099999   62.171     ]\n",
            "  [  79.1          62.171        70.19         62.171     ]\n",
            "  [  70.19         62.17099994   62.171        70.18999999]]]\n",
            "episode::  3\n",
            "[[[   0.            0.            0.            0.        ]\n",
            "  [  89.         -100.           79.1         100.        ]\n",
            "  [   0.            0.            0.            0.        ]]\n",
            "\n",
            " [[   0.            0.            0.            0.        ]\n",
            "  [  89.           70.19         70.19       -100.        ]\n",
            "  [-100.           70.19         62.171        79.1       ]]\n",
            "\n",
            " [[-100.           70.19         62.17099999   62.171     ]\n",
            "  [  79.1          62.171        70.19         62.171     ]\n",
            "  [  70.19         62.17099994   62.171        70.18999999]]]\n",
            "[[[   0.            0.            0.            0.        ]\n",
            "  [  89.         -100.           79.1         100.        ]\n",
            "  [   0.            0.            0.            0.        ]]\n",
            "\n",
            " [[   0.            0.            0.            0.        ]\n",
            "  [  89.           70.19         70.19       -100.        ]\n",
            "  [-100.           70.19         62.171        79.1       ]]\n",
            "\n",
            " [[-100.           70.19         62.17099999   62.171     ]\n",
            "  [  79.1          62.171        70.19         62.171     ]\n",
            "  [  70.19         62.17099994   62.171        70.18999999]]]\n",
            "[[[   0.            0.            0.            0.        ]\n",
            "  [  89.         -100.           79.1         100.        ]\n",
            "  [   0.            0.            0.            0.        ]]\n",
            "\n",
            " [[   0.            0.            0.            0.        ]\n",
            "  [  89.           70.19         70.19       -100.        ]\n",
            "  [-100.           70.19         62.171        79.1       ]]\n",
            "\n",
            " [[-100.           70.19         62.17099999   62.171     ]\n",
            "  [  79.1          62.171        70.19         62.171     ]\n",
            "  [  70.19         62.17099994   62.171        70.18999999]]]\n",
            "[[[   0.            0.            0.            0.        ]\n",
            "  [  89.         -100.           79.1         100.        ]\n",
            "  [   0.            0.            0.            0.        ]]\n",
            "\n",
            " [[   0.            0.            0.            0.        ]\n",
            "  [  89.           70.19         70.19       -100.        ]\n",
            "  [-100.           70.19         62.171        79.1       ]]\n",
            "\n",
            " [[-100.           70.19         62.17099999   62.171     ]\n",
            "  [  79.1          62.171        70.19         62.171     ]\n",
            "  [  70.19         62.17099994   62.171        70.18999999]]]\n",
            "episode::  4\n",
            "[[[   0.            0.            0.            0.        ]\n",
            "  [  89.         -100.           79.1         100.        ]\n",
            "  [   0.            0.            0.            0.        ]]\n",
            "\n",
            " [[   0.            0.            0.            0.        ]\n",
            "  [  89.           70.19         70.19       -100.        ]\n",
            "  [-100.           70.19         62.171        79.1       ]]\n",
            "\n",
            " [[-100.           70.19         62.17099999   62.171     ]\n",
            "  [  79.1          62.171        70.19         62.171     ]\n",
            "  [  70.19         62.17099994   62.171        70.18999999]]]\n",
            "[[[   0.            0.            0.            0.        ]\n",
            "  [  89.         -100.           79.1         100.        ]\n",
            "  [   0.            0.            0.            0.        ]]\n",
            "\n",
            " [[   0.            0.            0.            0.        ]\n",
            "  [  89.           70.19         70.19       -100.        ]\n",
            "  [-100.           70.19         62.171        79.1       ]]\n",
            "\n",
            " [[-100.           70.19         62.17099999   62.171     ]\n",
            "  [  79.1          62.171        70.19         62.171     ]\n",
            "  [  70.19         62.17099994   62.171        70.18999999]]]\n",
            "[[[   0.            0.            0.            0.        ]\n",
            "  [  89.         -100.           79.1         100.        ]\n",
            "  [   0.            0.            0.            0.        ]]\n",
            "\n",
            " [[   0.            0.            0.            0.        ]\n",
            "  [  89.           70.19         70.19       -100.        ]\n",
            "  [-100.           70.19         62.171        79.1       ]]\n",
            "\n",
            " [[-100.           70.19         62.17099999   62.171     ]\n",
            "  [  79.1          62.171        70.19         62.171     ]\n",
            "  [  70.19         62.17099994   62.171        70.18999999]]]\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#display a few shortest paths\n",
        "print(get_shortest_path(2, 2)) #starting at row 3, column 9\n",
        "# print(get_shortest_path(5, 0)) #starting at row 5, column 0\n",
        "# print(get_shortest_path(9, 5)) #starting at row 9, column 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpcZ83maZ4UN",
        "outputId": "4a1e42f5-48c0-42f2-f425-c1e2af540473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 2], [1, 2], [1, 1], [0, 1], [0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "61XE3v9ZZ8E0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}